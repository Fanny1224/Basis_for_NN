{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ff47c49-a18b-4a7b-ade2-ec9e03aab508",
   "metadata": {},
   "source": [
    "<img src=\"./fig/NNandDL.png\" width=\"80%\">  \n",
    "\n",
    "### <font color=green>**循环神经网络**  \n",
    "带有反向传播-记忆功能的神经网络  \n",
    "\n",
    "#### <font color=green>**Why RNN?**  \n",
    "- **前馈网络的问题**  \n",
    "  对于CNN这种前馈网络，相邻两层之间存在单向连接，层内无连接→有向无环图  \n",
    "  输入和输出维数固定，神经元数量固定→无法处理变长的序列数据  \n",
    "  每次网络的输出只依赖于当前输入→没有记忆  \n",
    "- **可计算问题**  \n",
    "  函数-前馈网络  \n",
    "  有限状态机&图灵机  需要记忆能力  \n",
    "\n",
    "#### <font color=green>**有哪些能够实现记忆的模型？**  \n",
    "- **时延神经网络TDNN**  \n",
    "  建立额外延时单元，用以储存网络的历史信息（输入、输出、隐状态）\n",
    "  简单来说就是给函数的各个变量加一个时间下标  \n",
    "  短期记忆能力  \n",
    "  <img src=\"./fig/TDNN.png\" width=\"30%\">  \n",
    "- **自回归模型AR**  \n",
    "  一类时间序列模型 用自己过去的值$y_{t-i}$ 预测 现在的值$y_{t}$\n",
    "  \n",
    "- **有外部输入的非线性自回归模型NARX**  \n",
    "  <img src=\"./fig/NARX.png\" width=\"40%\">  \n",
    "- **循环神经网络**  \n",
    "\n",
    "#### **<font color=green>循环神经网络RNN**  \n",
    "利用带自反馈的神经元，处理任意长度的时序数据  \n",
    "<img src=\"./fig/RNN.png\" width=\"40%\">  \n",
    "一种比前馈神经网络更符合生物神经网络的结构  \n",
    "广泛运用于语音识别、语言模型、自然语言等和时序相关的生成任务上  \n",
    "将循环神经网络按时间展开  \n",
    "<img src=\"./fig/timeexpand.png\" width=\"40%\">  \n",
    "时间维度上很深，非时间维上很浅  \n",
    "\n",
    "- **简单循环神经网络SRN**  \n",
    "  状态更新的方式： $h_{t}=f(Uh_{t-1}+Wx_{t}+b)$  \n",
    "  Theorem:一个完全连接的循环神经网络是任何非线性动力系统的近似器  \n",
    "  图灵完备性：完全连接的循环神经网络可近似解决所有可计算问题  \n",
    "- **RNN的作用**  \n",
    "    - 输入输出映射-机器学习模型  \n",
    "    - 存储器-联想记忆模型Hopfield  \n",
    "\n",
    "- **将循环神经网络应用到机器学习**  \n",
    "    - 序列到类别（指输入与输出）  \n",
    "    <img src=\"./fig/seqcat.png\" width=\"40%\">  \n",
    "    $h_{T}$包含所有的序列信息：有点太长了→改为按时间平均采样  \n",
    "    e.g 对文本序列记性情感分类  \n",
    "    汉字转向量→一串汉字作为一个时间序列  \n",
    "    - 同步的序列到序列  \n",
    "    <img src=\"./fig/seqseq.png\" width=\"40%\">  \n",
    "     输入与输出具有一一对应关系  \n",
    "     e.g.1 中文分词问题 把一句句子分成词语 S-单字词 B-词语开始 E-词语结束  \n",
    "     e.g.2 信息抽取 从无结构文本中抽取结构化信息形成知识  \n",
    "     e.g.3 语音识别 CTC模型  \n",
    "    - 异步的序列到序列模式  \n",
    "    即错位的对应关系，还有自回归性  \n",
    "    <img src=\"./fig/wrongseqseq.png\" width=\"40%\">  \n",
    "    e.g 机器翻译 每步生成一个词  \n",
    "\n",
    "- **参数学习**  \n",
    "定义损失  \n",
    "<img src=\"./fig/indexlearn.png\" width=\"40%\">  \n",
    "计算损失函数的梯度  \n",
    "<img src=\"./fig/RNNgrad.png\" width=\"40%\">  \n",
    "U在所有$h$的连接上，W在所有$x$到$h$的连接上  \n",
    "<img src=\"./fig/gradcal.png\" width=\"20%\">  \n",
    "**随时间的反向传播算法BPTT**  \n",
    "做一个近似：每个点的导数不依赖于时间，就会发现$t-k \\to \\infty$时发生梯度消失或梯度爆炸  \n",
    "这等效于一个截断效果！→**长程依赖问题**  \n",
    "由于梯度爆炸或消失，实际上只能学习短周期的依赖关系  \n",
    "\n",
    "- **如何解决长程依赖问题**  \n",
    "    - $\\gamma=1$？  \n",
    "      精心挑选参数以在初始化时使它为1  \n",
    "      循环边改为线性依赖关系$h_{t}=h_{t-1}+g(Wx_{t}+b)$  \n",
    "      但是这样模型能力会变弱，所以进一步在$g$上增加一些关于$h_{t-1}$的非线性项（有点类似残差网络）  \n",
    "    - 对梯度爆炸-权重衰减或权重截断  \n",
    "    - 对梯度消失问题-优化模型  \n",
    "\n",
    "- **常用的循环神经网络模型**  \n",
    "为解决长程依赖问题引入门控机制-控制信息的累积速度，有选择地加入新的信息，有选择的遗忘之前累积的信息  \n",
    "基于门控的循环神经网络 Gated RNN  \n",
    "    - 门控循环单元 GRU  \n",
    "    - 长短期记忆网络LST  \n",
    "- **GRU**  \n",
    "用更新门$z_{t}$控制线性与非线性信息的比例    \n",
    "<img src=\"./fig/renew.png\" width=\"40%\">  \n",
    "用重置门$r_{t}$进一步控制序列信息和输入信息的比例  \n",
    "<img src=\"./fig/reset.png\" width=\"40%\">  \n",
    "整个GRU的结构  \n",
    "<img src=\"./fig/GRU.png\" width=\"40%\">  \n",
    "\n",
    "- **长短期记忆神经网络LSTM**  \n",
    "<img src=\"./fig/LSTM.png\" width=\"40%\">  \n",
    "引入新的内部记忆单元$c$作为线性项，更好地释放$h$训练非线性  \n",
    "$c_{t}$由输入门$i_{t}$和遗忘门$f_{t}$组成  \n",
    "LSTM的一些变体  \n",
    "<img src=\"./fig/LSTMchange.png\" width=\"40%\">  \n",
    "\n",
    "- **深层循环神经网络**  \n",
    "增加非时间维度上的深度  \n",
    "    - **堆叠循环神经网络**  \n",
    "      <img src=\"./fig/stackRNN.png\" width=\"40%\">  \n",
    "      井字形展开模型\n",
    "      或者一些变体：某一层可以接受来自下一层的所有时刻的信息/某一个时刻可以接受该时刻所有层的信息  \n",
    "    - **双向循环神经网络**  \n",
    "      <img src=\"./fig/mutualRNN.png\" width=\"40%\">  \n",
    "      既可以按照顺时序建模，也可以按照逆时序建模→可以获得来自两个方向的信息  \n",
    "\n",
    "- **循环神经网络应用**  \n",
    "    - 自然语言理解  \n",
    "      一个句子的可能性/合理性 通过打分判断  \n",
    "      如何打分？  \n",
    "      <img src=\"./fig/nlanguage.png\" width=\"40%\">  \n",
    "      <img src=\"./fig/languagemodel.png\" width=\"40%\">  \n",
    "    - 机器翻译  \n",
    "      传统方式  \n",
    "      <img src=\"./fig/translate.png\" width=\"40%\">  \n",
    "      RNN方式：很自然地得到词语排列顺序  \n",
    "    - 看图说话  \n",
    "      CNN+RNN  \n",
    "      <img src=\"./fig/imagecontent.png\" width=\"40%\">  \n",
    "    - 写字  \n",
    "      把每一个字母看做一连串的点，一个字母的写法是每一个点相对于前一个点的偏移量；再增加一维判断是否要提笔  \n",
    "    - 问答模型  \n",
    "      <img src=\"./fig/communication.png\" width=\"40%\">  \n",
    "      把问题/对话 作为可被记忆的历史序列  \n",
    "\n",
    "- **扩展到图结构**\n",
    "序列（循环神经网络）→树（递归神经网络）→图（图网络）  \n",
    "    - 树结构  \n",
    "      程序语言/自然语言的句法结构  \n",
    "      递归神经网络在一个有向无循环（树）上共享一个组合函数  \n",
    "      <img src=\"./fig/tree.png\" width=\"40%\">  \n",
    "      递归神经网络可以退化为循环神经网络  \n",
    "    - 图网络  \n",
    "      <img src=\"./fig/imgnet.png\" width=\"40%\">  \n",
    "      定义图、节点与连接  \n",
    "      更新一张图：根据连接节点+全局更新边；根据边+全局再更新节点，最后根据新的图更新全局信息  \n",
    "      更新函数&读出函数  \n",
    "\n",
    "### **<font color=green>注意力机制与外部记忆**  \n",
    "这两个是部件级别的模块-可以与其他的网络相融合，增强网络的能力    \n",
    "#### **<font color=green>注意力机制**  \n",
    "如何在大量信息中筛选出相关的信息  \n",
    "- **注意力机制**  \n",
    "  why要引入注意力机制？ e.g 阅读理解  \n",
    "  类似于大脑，每时每刻接收的信息非常多；如何解决信息超载?→注意力集中  \n",
    "    - 自下而上  \n",
    "      自动地被突出的信息吸引--汇聚pooling  \n",
    "    - 自上而下\n",
    "      主动根据任务将注意力集中到某一方面--汇聚focus  \n",
    "      我们期望在机器学习中实现的应该是这样一种注意力机制  \n",
    "      从输入向量中筛选出和q相关的  \n",
    "      <img src=\"./fig/focus.png\" width=\"30%\">  \n",
    "      hard attention - 只找到最相关的→离散无梯度，要用强化学习    \n",
    "      soft attention - 按相关度对所有信息进行加权汇总  \n",
    "      <img src=\"./fig/softattention.png\" width=\"40%\">  \n",
    "      有哪些注意力打分函数  \n",
    "      <img src=\"./fig/attentionevaluate.png\" width=\"30%\">  \n",
    "      变体：键值对注意力 key-value pair attention  \n",
    "      <img src=\"./fig/pairattention.png\" width=\"40%\">  \n",
    "      变体：多头注意力 multi-head attention  \n",
    "      用多个查询同时从输入信息中读取多组信息；每个注意力头关注输入信息的不同部分  \n",
    "    - 指针网络 \n",
    "      只利用注意力机制中的第一步，将注意力分布作为一个软性指针指出相关信息  \n",
    "      比如在阅读理解中指出答案所在的位置  \n",
    "\n",
    "- **注意力机制的应用**  \n",
    "    - 文本分类问题  \n",
    "      可以根据不同的标准 e.g,情感分类 对象分类  使用不同的筛选向量$q$  \n",
    "      <img src=\"./fig/textsort.png\" width=\"40%\">  \n",
    "    - 机器翻译的优化  \n",
    "      传统RNN一般采用序列-序列的机器翻译模式  但序列重建事实上是比较复杂的任务  \n",
    "      采用注意力机制后 可以在每次获取下一个词时集中注意力到上一个词的上下文结构 即$h_{t-1}=q_{t}$  \n",
    "      <img src=\"./fig/atttranslate.png\" width=\"40%\">  \n",
    "      <img src=\"./fig/attentionshow.png\" width=\"30%\"> 注意力分布示意图  \n",
    "    - Image Caption  \n",
    "      每次集中注意力于图像的不同部位以生成对应的词语  \n",
    "      <img src=\"./fig/attimgcap.png\" width=\"40%\">  \n",
    "    - 阅读理解  \n",
    "      一种双向的注意力机制 从问题筛选原文+从原文筛选问题  \n",
    "      <img src=\"./fig/readcom.png\" width=\"30%\">  \n",
    "\n",
    "- **变长序列建模--自注意力模型**  \n",
    "处理变长序列时，可以使用RNN/CNN来得到一个相同长度的输出序列  But这样的到的依赖关系是local的  \n",
    "<img src=\"./fig/changelen.png\" width=\"40%\">  \n",
    "→建立非局部的依赖关系  全连接→自注意力模型  \n",
    "每个输出会与所有的输入信息有关，但所占的权重由神经网络本身的动态计算决定  \n",
    "可以想象动态的网络连接方式，而查询$q$是由当前的输入信息自身决定的  \n",
    "<img src=\"./fig/selfatten.png\" width=\"40%\">  \n",
    "用向量点乘与求和的方法计算权重  \n",
    "自注意力模型的矩阵表示  \n",
    "<img src=\"./fig/selfattenmatrix.png\" width=\"40%\">  \n",
    "    - 对自注意力模型的优化  \n",
    "      QKV模式  \n",
    "      对原向量用不同的矩阵进行处理后 分开query-key-value三者  \n",
    "      <img src=\"./fig/QKV.png\" width=\"40%\">  \n",
    "      <img src=\"./fig/QKVcal.png\" width=\"40%\">  \n",
    "      进一步优化还可以采用多头QKV模式  \n",
    "      同时对输入序列的多个特征进行计算  \n",
    "      <img src=\"./fig/multiQKV.png\" width=\"40%\">  \n",
    "\n",
    "- **Transformer**  \n",
    "  一套完整的自注意力网络只有自注意力机制是不够的的  \n",
    "  <img src=\"./fig/selfattennet.png\" width=\"40%\">  \n",
    "  其他操作：位置编码（包括进位置信息）、层归一化（为了能有更深的网络）、直连边、逐位的FFN（类似于做一个卷积操作） \n",
    "  相当于每个点都动态地与其他所有点相连  \n",
    "  <img src=\"./fig/selfattenill.png\" width=\"40%\">  \n",
    "  复杂度分析  \n",
    "  <img src=\"./fig/complexdegree.png\" width=\"40%\">  \n",
    "  整个transformer的encode和decode架构  \n",
    "  decode的特殊指出 mask attention（只能看到前面不能看到后面）+cross attention \n",
    "  需要经过大量数据预训练，避免在小数据集上的过拟合  \n",
    "\n",
    "- **外部记忆**  \n",
    "人的记忆：外部信息在人脑中的显示  \n",
    "记忆过程：短期记忆→情感记忆→结构/长期记忆  \n",
    "特点：联想记忆 只能靠相似的记忆触发 而不能像计算机一样直接寻址  \n",
    "<img src=\"./fig/memory.png\" width=\"40%\">  \n",
    "通常人脑中的记忆容量很少 →如何增加记忆容量？ 外部记忆网络  \n",
    "主网络与外部记忆单元可以记性读写操作  \n",
    "<img src=\"./fig/MNN.png\" width=\"40%\">  \n",
    "外部记忆单元如何设置？①结构化②联想记忆  \n",
    "    - 结构化外部记忆  \n",
    "      典型的是矩阵  \n",
    "      如何读写？  \n",
    "      在主网络中定义查询向量去外部记忆单元中查找（soft）  \n",
    "      比如阅读理解中 把整个story作为外部记忆（只读）  \n",
    "      <img src=\"./fig/outsidememory.png\" width=\"40%\">  \n",
    "      可读写的：神经图灵机  \n",
    "      用注意力机制产生一个寻址 在memory中读与写  \n",
    "\n",
    "### **<font color=green>无监督学习**  \n",
    "#### **<font color=green>What and Why?**  \n",
    "监督学习：建立输入与输出的映射关系→在未知数据上的损失能够最小  \n",
    "无监督学习：从无标签的数据中学习出一些有用的模式 \n",
    "典型问题：  \n",
    "- 聚类问题  \n",
    "  纵向结构 对一堆特征进行分类  \n",
    "- 特征学习  \n",
    "  横向特征 去除不相关的信息 e.g 主成分分析PCA  \n",
    "- 密度估计  \n",
    "  估计所有数据的分布 $P(x)$  得到其背后的分布规律  \n",
    "<img src=\"./fig/unmonitored.png\" width=\"40%\">  \n",
    "\n",
    "#### **<font color=green>聚类问题**  \n",
    "将样本中相似的样本分配到相同的cluster  \n",
    "如何定义样本间的距离--相似性？  \n",
    "欧式距离、余弦距离（夹角）、相关距离 etc  \n",
    "常见的聚类任务：图像分割、文本聚类、社交网络分析 etc  \n",
    "- **cluster**  \n",
    "  没有严格的定义，只是一组相似的样本  \n",
    "- **距离衡量**  \n",
    "  <img src=\"./fig/dcal.png\" width=\"40%\">  \n",
    "- **判断聚类好坏**  \n",
    "  外部指标 根据已知的是否同类与算出的是否同类去计算 Jaccard系数   \n",
    "  <img src=\"./fig/Jaccard.png\" width=\"40%\">   \n",
    "  内部指标：没有已知的分类结果作为参考  \n",
    "  类内间距明显小于类间间距 DB指数越小越好  \n",
    "  <img src=\"./fig/DB.png\" width=\"40%\">  \n",
    "- **常用聚类方法**  \n",
    "    - K均值方法  \n",
    "      <img src=\"./fig/Kmean.png\" width=\"40%\">  \n",
    "      确定类别的数量→随机生成3个类中心→根据距离得到分类→根据划分重新计算每个类的类中心→再重复上述步骤 不断迭代直到收敛  \n",
    "      K均值分类的目标函数-刻画聚类好坏 每个类的样本点到其类中心的平均距离  \n",
    "      <img src=\"./fig/Kgoal.png\" width=\"40%\">  \n",
    "      超参数K应该如何选择？  \n",
    "      <img src=\"./fig/Kchoice.png\" width=\"40%\">  \n",
    "      一般选择开始平缓下降后过一段  \n",
    "      如何初始化K中心？  \n",
    "      大于最小间距的随机样本点/K个相互距离最远的点/等距网格点  \n",
    "      K均值的优缺点：  \n",
    "      <img src=\"./fig/Kaddis.png\" width=\"40%\">  \n",
    "    - 层次聚类  \n",
    "      计算不同类别的点之间的相似度来创建一颗有层次嵌套的聚类树！  \n",
    "      聚合-自底向上/分裂-自顶向下  \n",
    "          - 聚合过程  \n",
    "            先把每个样本分到单独的类→计算两类簇之间的距离，找到距离最小的两个并合并为一个类簇→重复上述过程  \n",
    "          - 分裂过程  \n",
    "            先把所有样本划分为同一个类→找到距离最远的两个样本并划分到不同的类→按照距离这两个点的距离哪个更近将样本划分到对应的类簇中→重复以上过程  \n",
    "      优缺点  \n",
    "      <img src=\"./fig/clusteraddis.png\" width=\"40%\">  \n",
    "\n",
    "\n",
    "#### <font color=green>**无监督特征学习**  \n",
    "从原始特征空间中学习出更有用的特征编码方式  \n",
    "新的编码也可以被解码并回复到原空间  \n",
    "特征学习的应用  \n",
    "<img src=\"./fig/charalearnapp.png\" width=\"40%\">  \n",
    "\n",
    "- **典型方法：主成分分析**  \n",
    "  数据的原始特征可能存在的问题：高维→维度灾难、过拟合；冗余性→学习效果差；  \n",
    "  解决方式：降维  \n",
    "  最常用的数据降维方法-线性投影 $z=W_{\\mathrm{T}}x$，且$W$满足归一化  \n",
    "  <img src=\"./fig/PCA.png\" width=\"40%\">  \n",
    "  信息论的角度来讲，方差越大，所含信息量越大  \n",
    "  两个优化准则是等价的  \n",
    "  <img src=\"./fig/PCAcal.png\" width=\"40%\">  \n",
    "  最后两边同时左乘W转置，得到方差最大即为$\\lambda$最大  \n",
    "  解特征值矩阵即可得到$\\lambda$和$W$  \n",
    "\n",
    "- **编码与稀疏编码**  \n",
    "  给定一组基向量，将输入样本表示为这些基向量的线性组合，组合系数即为对应编码  \n",
    "  再把编码乘以字典，即可还原回输入样本  \n",
    "  解码误差尽可能小→学习最好的字典与基向量  \n",
    "  字典在所有样本上共享学习  \n",
    "  问题：不止一个无误差的字典-过完备  \n",
    "  <img src=\"./fig/overcomplete.png\" width=\"40%\">  \n",
    "  →稀疏编码：找到一组过完备的基向量来进行编码  \n",
    "  每个原始特征都可以由少数的基向量组合而成（更类似于人脑的信息处理特征）  \n",
    "  <img src=\"./fig/spcode.png\" width=\"40%\">  \n",
    "  优化方式：分别固定基向量与编码，并优化另一者  \n",
    "  稀疏编码的优点：降低后续计算量，非零的值很少；可解释性强；便于特征选择，自动忽略为零的那些向量  \n",
    "\n",
    "- **自编码器**  \n",
    "  需要学习所有的编码$f$与解码$g$过程  \n",
    "  编码与解码都可以是非线性的（线性时就退化为了PCA）  \n",
    "  学习的目标函数：重构错误  \n",
    "  两层神经网络结构的自编码器  \n",
    "  <img src=\"./fig/twolayercoder.png\" width=\"40%\">  \n",
    "  可以类似地做更深的编码器与解码器  \n",
    "  同样可以给自编码器加上稀疏性限制  \n",
    "  降噪编码器：通过手动引入噪声（比如以随机比例将一些值设为0得到一个被破坏的向量） 并训练出能够透过噪声还原原信息的模型 增加鲁棒性  \n",
    "\n",
    "#### <font color=green>**自监督学习**  \n",
    "不是以输入重构作为目标，而是在无标签样本寻找更多样的目标  \n",
    "e.g past→future left→right bottom→top  part of the input→ another part  \n",
    "自行构造监督信号  \n",
    "图片旋转；文本任务中：掩码语言模型（掩盖掉一些词并还原，学习到非常好的模型）  \n",
    "SSL is the future!  \n",
    "\n",
    "#### <font color=green>**概率密度估计**  \n",
    "- 参数密度估计  \n",
    "  先验地假设样本服从某种分布，再根据数据训练参数 最大似然法    \n",
    "  正态分布（连续）& 多项分布（离散）  \n",
    "  问题：如何选择密度函数；不可观测变量问题；维度灾难问题-随维度增加样本指数增加、样本不足是容易导致过拟合；  \n",
    "- 非参数密度估计  \n",
    "  将样本空间划分为不同区域，估计每个区域的概率来近似数据的概率密度函数  \n",
    "  <img src=\"./fig/nonparacal.png\" width=\"40%\">  \n",
    "  直方图密度估计  \n",
    "  <img src=\"./fig/nonparashow.png\" width=\"40%\">  \n",
    "  区间选择大-曲线平滑，但可能丢失特征；区间选择过小-不平滑，部分区域估计不准确  \n",
    "  直方图密度估计的改进：核密度估计  \n",
    "  <img src=\"./fig/corecal.png\" width=\"40%\">  \n",
    "  K近邻方法-核密度估计的逆向方法  \n",
    "  估计附近有K个样本点所需包括的面积  \n",
    "  K不能选取太小，不然会有很大随机性  \n",
    "  <img src=\"./fig/Kcal.png\" width=\"40%\">  \n",
    "- 参数密度估计 v.s 非参密度估计  \n",
    "后者需要保留整个训练集；而前者不需要，在储存和计算上更方便  \n",
    "\n",
    "#### <font color=green>**半监督学习**  \n",
    "<img src=\"./fig/halflearn.png\" width=\"40%\">  \n",
    " \n",
    "两种主要方式：\n",
    "- 自训练  \n",
    "  把本来那部分有标签的数据作为训练集→训练结果给测试集分类→可信度较高的分类结果归入训练集→开始新一轮训练  \n",
    "- 协同训练  \n",
    "  取出有标签数据的不同部分进行训练→训练结果再用以测试另外一部分→优化当前训练  \n",
    "<img src=\"./fig/twohalftrain.png\" width=\"40%\">\n",
    "\n",
    "\n",
    "      \n",
    "\n",
    "       \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  \n",
    "  \n",
    "  \n",
    "\n",
    "  \n",
    "  \n",
    "  \n",
    "  \n",
    "  \n",
    "  \n",
    "  \n",
    "  \n",
    "    \n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "955d2aea-4c3f-4249-af9f-52e74b3c2b24",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
